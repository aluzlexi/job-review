{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('glassdoor_reviews.csv')\n",
    "\n",
    "# df = df.drop(['date_review','current'], axis=1)\n",
    "\n",
    "# text_cols = df.select_dtypes(include='object').columns\n",
    "# for col in text_cols:\n",
    "#     df[col] = df[col].fillna('')\n",
    "    \n",
    "# def define_level(rating):\n",
    "#     if rating >= 4:\n",
    "#         return 'high'\n",
    "#     if rating <= 2:\n",
    "#         return 'low'\n",
    "#     return 'middle'\n",
    "\n",
    "# df['rating_level'] = df['overall_rating'].apply(lambda x: define_level(x))\n",
    "\n",
    "# df['combined_text'] = df[['headline', 'pros', 'cons']].apply(lambda x: ''.join(x), axis=1)\n",
    "\n",
    "# def deal_empty(string):\n",
    "#     if string.isspace():\n",
    "#         return \"\"\n",
    "#     else:\n",
    "#         return string\n",
    "\n",
    "# df['firm'] = df['firm'].apply(lambda x: deal_empty(x))\n",
    "# df['job_title'] = df['job_title'].apply(lambda x: deal_empty(x))\n",
    "# df['location'] = df['location'].apply(lambda x: deal_empty(x))\n",
    "\n",
    "# df.to_csv('UI_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>firm</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>overall_rating</th>\n",
       "      <th>work_life_balance</th>\n",
       "      <th>culture_values</th>\n",
       "      <th>diversity_inclusion</th>\n",
       "      <th>career_opp</th>\n",
       "      <th>comp_benefits</th>\n",
       "      <th>senior_mgmt</th>\n",
       "      <th>recommend</th>\n",
       "      <th>ceo_approv</th>\n",
       "      <th>outlook</th>\n",
       "      <th>headline</th>\n",
       "      <th>pros</th>\n",
       "      <th>cons</th>\n",
       "      <th>rating_level</th>\n",
       "      <th>combined_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFH-Wealth-Management</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>r</td>\n",
       "      <td>Young colleagues, poor micro management</td>\n",
       "      <td>Very friendly and welcoming to new staff. Easy...</td>\n",
       "      <td>Poor salaries, poor training and communication.</td>\n",
       "      <td>low</td>\n",
       "      <td>Young colleagues, poor micro managementVery fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFH-Wealth-Management</td>\n",
       "      <td>Office Administrator</td>\n",
       "      <td>Bromsgrove, England, England</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>r</td>\n",
       "      <td>Excellent staff, poor salary</td>\n",
       "      <td>Friendly, helpful and hard-working colleagues</td>\n",
       "      <td>Poor salary which doesn't improve much with pr...</td>\n",
       "      <td>low</td>\n",
       "      <td>Excellent staff, poor salaryFriendly, helpful ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AFH-Wealth-Management</td>\n",
       "      <td>Office Administrator</td>\n",
       "      <td>Bromsgrove, England, England</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>Low salary, bad micromanagement</td>\n",
       "      <td>Easy to get the job even without experience in...</td>\n",
       "      <td>Very low salary, poor working conditions, very...</td>\n",
       "      <td>low</td>\n",
       "      <td>Low salary, bad micromanagementEasy to get the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AFH-Wealth-Management</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>r</td>\n",
       "      <td>Over promised under delivered</td>\n",
       "      <td>Nice staff to work with</td>\n",
       "      <td>No career progression and salary is poor</td>\n",
       "      <td>high</td>\n",
       "      <td>Over promised under deliveredNice staff to wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFH-Wealth-Management</td>\n",
       "      <td>Office Administrator</td>\n",
       "      <td>Bromsgrove, England, England</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>client reporting admin</td>\n",
       "      <td>Easy to get the job, Nice colleagues.</td>\n",
       "      <td>Abysmal pay, around minimum wage. No actual tr...</td>\n",
       "      <td>low</td>\n",
       "      <td>client reporting adminEasy to get the job, Nic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    firm              job_title                      location  \\\n",
       "0  AFH-Wealth-Management                    NaN                           NaN   \n",
       "1  AFH-Wealth-Management   Office Administrator  Bromsgrove, England, England   \n",
       "2  AFH-Wealth-Management   Office Administrator  Bromsgrove, England, England   \n",
       "3  AFH-Wealth-Management                    NaN                           NaN   \n",
       "4  AFH-Wealth-Management   Office Administrator  Bromsgrove, England, England   \n",
       "\n",
       "   overall_rating  work_life_balance  culture_values  diversity_inclusion  \\\n",
       "0               2                4.0             3.0                  NaN   \n",
       "1               2                3.0             1.0                  NaN   \n",
       "2               1                1.0             1.0                  NaN   \n",
       "3               5                2.0             3.0                  NaN   \n",
       "4               1                2.0             1.0                  NaN   \n",
       "\n",
       "   career_opp  comp_benefits  senior_mgmt recommend ceo_approv outlook  \\\n",
       "0         2.0            3.0          3.0         x          o       r   \n",
       "1         2.0            1.0          4.0         x          o       r   \n",
       "2         1.0            1.0          1.0         x          o       x   \n",
       "3         2.0            2.0          3.0         x          o       r   \n",
       "4         2.0            1.0          1.0         x          o       x   \n",
       "\n",
       "                                  headline  \\\n",
       "0  Young colleagues, poor micro management   \n",
       "1             Excellent staff, poor salary   \n",
       "2          Low salary, bad micromanagement   \n",
       "3            Over promised under delivered   \n",
       "4                   client reporting admin   \n",
       "\n",
       "                                                pros  \\\n",
       "0  Very friendly and welcoming to new staff. Easy...   \n",
       "1      Friendly, helpful and hard-working colleagues   \n",
       "2  Easy to get the job even without experience in...   \n",
       "3                            Nice staff to work with   \n",
       "4              Easy to get the job, Nice colleagues.   \n",
       "\n",
       "                                                cons rating_level  \\\n",
       "0    Poor salaries, poor training and communication.          low   \n",
       "1  Poor salary which doesn't improve much with pr...          low   \n",
       "2  Very low salary, poor working conditions, very...          low   \n",
       "3           No career progression and salary is poor         high   \n",
       "4  Abysmal pay, around minimum wage. No actual tr...          low   \n",
       "\n",
       "                                       combined_text  \n",
       "0  Young colleagues, poor micro managementVery fr...  \n",
       "1  Excellent staff, poor salaryFriendly, helpful ...  \n",
       "2  Low salary, bad micromanagementEasy to get the...  \n",
       "3  Over promised under deliveredNice staff to wor...  \n",
       "4  client reporting adminEasy to get the job, Nic...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('UI_data.csv', index_col = 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting myapp.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile myapp.py\n",
    "import streamlit as st\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from textblob import TextBlob\n",
    "import seaborn as sns\n",
    "\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "### Data Import ###\n",
    "df = pd.read_csv('UI_data.csv', index_col = 0)\n",
    "color_dict = {'1. FC Köln': '#fc4744', '1. FC Nürnberg':'#8c0303', '1. FC Union Berlin':'#edd134', '1. FSV Mainz 05':'#fa2323', 'Bayer 04 Leverkusen':'#cf0c0c', 'Bayern München':'#e62222', 'Bor. Mönchengladbach':'#1f9900', 'Borussia Dortmund':'#fff830', 'Eintracht Braunschweig':'#dbca12', 'Eintracht Frankfurt':'#d10606', 'FC Augsburg':'#007512', 'FC Ingolstadt 04':'#b50300', 'FC Schalke 04':'#1c2afc', 'Fortuna Düsseldorf':'#eb3838', 'Hamburger SV':'#061fc2', 'Hannover 96':'#127a18', 'Hertha BSC':'#005ac2', 'RB Leipzig':'#0707a8', 'SC Freiburg':'#d1332e', 'SC Paderborn 07':'#0546b5', 'SV Darmstadt 98':'#265ade', 'TSG Hoffenheim':'#2b82d9', 'VfB Stuttgart':'#f57171', 'VfL Wolfsburg':'#38d433', 'Werder Bremen':'#10a30b'}\n",
    "ratings = ['overall_rating','work_life_balance','culture_values','diversity_inclusion','career_opp','comp_benefits','senior_mgmt']\n",
    "\n",
    "st.set_page_config(layout=\"wide\")\n",
    "\n",
    "def plot_rating(df): #df is filtered\n",
    "    rc = {'figure.figsize':(6,3),\n",
    "          'axes.facecolor':'white',\n",
    "          'axes.edgecolor': 'white',\n",
    "          'axes.labelcolor': 'grey',\n",
    "          'figure.facecolor': 'white',\n",
    "          'patch.edgecolor': 'white',\n",
    "          'text.color': 'grey',\n",
    "          'xtick.color': 'grey',\n",
    "          'ytick.color': 'grey',\n",
    "          'grid.color': 'grey',\n",
    "          'font.size' : 8,\n",
    "          'axes.labelsize': 12,\n",
    "          'xtick.labelsize': 8,\n",
    "          'ytick.labelsize': 12}\n",
    "    \n",
    "    plt.rcParams.update(rc)\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    if not sort_rating:\n",
    "        df_plot = df[ratings].mean()    \n",
    "    else:\n",
    "        df_plot = df[ratings].mean().sort_values(ascending=False)\n",
    "        \n",
    "    if compare_analysis_rating:\n",
    "        df_plot_2 = filtered_df_2[ratings].mean()\n",
    "        \n",
    "        # create DataFrame for df_plot and df_plot_2 separately\n",
    "        df_plot = pd.DataFrame({'values': df_plot.values, 'group': 'original'}, index=df_plot.index)\n",
    "        df_plot_2 = pd.DataFrame({'values': df_plot_2.values, 'group': 'new'}, index=df_plot_2.index)\n",
    "\n",
    "        # concatenate vertically to create a new DataFrame\n",
    "        compare_plot = pd.concat([df_plot, df_plot_2])\n",
    "\n",
    "        # plot a double bar chart using seaborn\n",
    "        sns.barplot(data=compare_plot, x=compare_plot.index, y='values', hue='group', palette=['#6dcd8d', '#7cb4d6'])\n",
    "        ax.legend(loc = 'lower right')\n",
    "    else:\n",
    "        ax = sns.barplot(x=df_plot.index, y=df_plot.values, color = \"#6dcd8d\")\n",
    "        \n",
    "    ax.set(xlabel = \"Rating Aspect\", ylabel = \"Rating Score\")\n",
    "    plt.xticks(rotation=66, horizontalalignment=\"right\")\n",
    "    for p in ax.patches:\n",
    "        ax.annotate(format(p.get_height(), '.2f'), \n",
    "              (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "               ha = 'center',\n",
    "               va = 'center', \n",
    "               xytext = (0, 18),\n",
    "               textcoords = 'offset points')\n",
    "    st.pyplot(fig)\n",
    "    \n",
    "    \n",
    "def extract_sentiment_measures(text):\n",
    "    blob = TextBlob(text)\n",
    "    sentiment_polarity = blob.sentiment.polarity\n",
    "    sentiment_subjectivity = blob.sentiment.subjectivity\n",
    "\n",
    "    return pd.Series({\n",
    "        'sentiment_polarity': sentiment_polarity,\n",
    "        'sentiment_subjectivity': sentiment_subjectivity,\n",
    "    })\n",
    "\n",
    "def plot_sentiment(df): #df is filtered\n",
    "    rc = {'figure.figsize':(6,3),\n",
    "          'axes.facecolor':'white',\n",
    "          'axes.edgecolor': 'white',\n",
    "          'axes.labelcolor': 'grey',\n",
    "          'figure.facecolor': 'white',\n",
    "          'patch.edgecolor': 'white',\n",
    "          'text.color': 'grey',\n",
    "          'xtick.color': 'grey',\n",
    "          'ytick.color': 'grey',\n",
    "          'grid.color': 'grey',\n",
    "          'font.size' : 8,\n",
    "          'axes.labelsize': 12,\n",
    "          'xtick.labelsize': 8,\n",
    "          'ytick.labelsize': 12}\n",
    "    \n",
    "    plt.rcParams.update(rc)\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    # apply the function to each row of the original DataFrame to create a new DataFrame\n",
    "    sentiment_df = df.iloc[:100,:]['combined_text'].apply(extract_sentiment_measures)\n",
    "    df_plot = sentiment_df.mean()    \n",
    "    ax = sns.barplot(x=df_plot.index, y=df_plot.values, color = \"#6dcd8d\")\n",
    "    ax.set(xlabel = \"Sentiment Aspect\", ylabel = \"Sentiment Score\")\n",
    "    for p in ax.patches:\n",
    "        ax.annotate(format(p.get_height(), '.2f'), \n",
    "              (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "               ha = 'center',\n",
    "               va = 'center', \n",
    "               xytext = (0, 18),\n",
    "               textcoords = 'offset points')\n",
    "    st.pyplot(fig)\n",
    "\n",
    "def plot_top_phrases(df): #df is filtered\n",
    "    rc = {'figure.figsize':(6,3),\n",
    "          'axes.facecolor':'white',\n",
    "          'axes.edgecolor': 'white',\n",
    "          'axes.labelcolor': 'grey',\n",
    "          'figure.facecolor': 'white',\n",
    "          'patch.edgecolor': 'white',\n",
    "          'text.color': 'grey',\n",
    "          'xtick.color': 'grey',\n",
    "          'ytick.color': 'grey',\n",
    "          'grid.color': 'grey',\n",
    "          'font.size' : 8,\n",
    "          'axes.labelsize': 12,\n",
    "          'xtick.labelsize': 8,\n",
    "          'ytick.labelsize': 12}\n",
    "    \n",
    "    plt.rcParams.update(rc)\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    if scope == \"all\":\n",
    "        processed_list = filtered_df[\"combined_text\"].apply(lambda x: nlp(x.lower()))\n",
    "    else:\n",
    "        processed_list = filtered_df[scope].apply(lambda x: nlp(x.lower()))\n",
    "          \n",
    "    # Extract noun phrases\n",
    "    noun_phrases = []\n",
    "    for doc in nlp.pipe(processed_list):\n",
    "        for chunk in doc.noun_chunks:\n",
    "            if chunk.text not in STOPWORDS:\n",
    "                noun_phrases.append(chunk.text)\n",
    "\n",
    "    # Count the frequency of each noun phrase\n",
    "    df_plot = pd.Series(noun_phrases).value_counts().head(n)    \n",
    "    ax = sns.barplot(x=df_plot.index, y=df_plot.values, color = \"#6dcd8d\")\n",
    "    ax.set_title(\"Top {} frequent noun phrases in {}\".format(n,scope))\n",
    "    ax.set(xlabel = \"Noun Phrase\", ylabel = \"Frequency\")\n",
    "    plt.xticks(rotation=66, horizontalalignment=\"right\")\n",
    "    for p in ax.patches:\n",
    "        ax.annotate(format(int(p.get_height()), 'd'), \n",
    "              (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "               ha = 'center',\n",
    "               va = 'center', \n",
    "               xytext = (0, 18),\n",
    "               textcoords = 'offset points')\n",
    "    st.pyplot(fig)\n",
    "\n",
    "def plot_wordcloud(df): #df is filtered\n",
    "    rc = {'figure.figsize':(6,3),\n",
    "          'axes.facecolor':'white',\n",
    "          'axes.edgecolor': 'white',\n",
    "          'axes.labelcolor': 'grey',\n",
    "          'figure.facecolor': 'white',\n",
    "          'patch.edgecolor': 'white',\n",
    "          'text.color': 'grey',\n",
    "          'xtick.color': 'grey',\n",
    "          'ytick.color': 'grey',\n",
    "          'grid.color': 'grey',\n",
    "          'font.size' : 8,\n",
    "          'axes.labelsize': 12,\n",
    "          'xtick.labelsize': 8,\n",
    "          'ytick.labelsize': 12}\n",
    "    \n",
    "    plt.rcParams.update(rc)\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    if scope_2 == \"all\":\n",
    "        text = ' '.join(filtered_df[\"combined_text\"]).lower()\n",
    "    else:\n",
    "        text = ' '.join(filtered_df[scope_2]).lower()\n",
    "\n",
    "    # Generate a WordCloud object with the text and set the parameters\n",
    "    wordcloud = WordCloud(stopwords=STOPWORDS, width=800, height=400, background_color='white', max_words=n_2, colormap='Greens').generate(text)\n",
    "    ax.imshow(wordcloud, interpolation='bilinear')\n",
    "    ax.axis('off')\n",
    "    st.pyplot(fig)\n",
    "\n",
    "\n",
    "####################\n",
    "### INTRODUCTION ###\n",
    "####################\n",
    "row0_spacer1, row0_1, row0_spacer2, row0_2, row0_spacer3 = st.columns((.1, 2.3, .1, 1.3, .1))\n",
    "with row0_1:\n",
    "    st.title('Glassdoor Job Reviews - Analyzer')\n",
    "with row0_2:\n",
    "    st.text(\"\")\n",
    "    st.subheader('Streamlit App by [Lexi Lu](https://www.linkedin.com/in/zilinlu/)')\n",
    "row3_spacer1, row3_1, row3_spacer2 = st.columns((.1, 3.2, .1))\n",
    "with row3_1:\n",
    "    st.markdown(\"This large dataset based on Glassdoor contains job descriptions and rankings among various criteria such as work-life balance, income, culture, etc. The data covers the various industry.\")\n",
    "    st.markdown(\"You can find the database available in [Kaggle](https://www.kaggle.com/datasets/davidgauthier/glassdoor-job-reviews)\")\n",
    "    st.markdown(\"You can find the source code in the [GitHub Repository](https://github.com/)\")\n",
    "    \n",
    "#################\n",
    "### SELECTION ###\n",
    "#################\n",
    "filtered_df = df.copy()\n",
    "\n",
    "st.sidebar.text('')\n",
    "st.sidebar.text('')\n",
    "st.sidebar.text('')\n",
    "st.sidebar.markdown(\"**Make your selections of interest here:** 👇\")\n",
    "### COMPANY ###\n",
    "firm_options = sorted([x for x in filtered_df['firm'].unique() if x != ''])\n",
    "firm = st.sidebar.selectbox('First select the company you want to analyze:', firm_options, key = \"option1_firm\")\n",
    "filtered_df = filtered_df[filtered_df['firm'] == firm]  \n",
    "\n",
    "### JOB TITLE ###\n",
    "job_options = sorted([str(x) for x in filtered_df['job_title'].unique() if x != ''])\n",
    "job_title = st.sidebar.multiselect('Then select one or multiple job titles (optional):', job_options, key = \"option1_job\")\n",
    "if job_title:\n",
    "    filtered_df = filtered_df[filtered_df['job_title'].isin(job_title)]     \n",
    "\n",
    "### LOCATION ###\n",
    "location_options = sorted([str(x) for x in filtered_df['location'].unique() if x != ''])\n",
    "location = st.sidebar.multiselect('Then select one or multiple locations (optional):', location_options, key = \"option1_loc\")\n",
    "if location:\n",
    "    filtered_df = filtered_df[filtered_df['location'].isin(location)]\n",
    "    \n",
    "### SEE DATA ###\n",
    "row6_spacer1, row6_1, row6_spacer2 = st.columns((.2, 7.1, .2))\n",
    "with row6_1:\n",
    "    st.subheader(\"Currently selected data:\")\n",
    "\n",
    "row2_spacer1, row2_1, row2_spacer2, row2_2, row2_spacer3, row2_3, row2_spacer4, row2_4, row2_spacer5   = st.columns((.2, 1.6, .2, 1.6, .2, 1.6, .2, 1.6, .2))\n",
    "with row2_1:\n",
    "    str_reviews = \"❤️ \" + str(filtered_df.shape[0]) + \" Reviews\"\n",
    "    st.markdown(str_reviews)\n",
    "with row2_2:\n",
    "    str_firms = \"🧡 \" + str(len(filtered_df['firm'].value_counts())) + \" Companies\"\n",
    "    st.markdown(str_firms)\n",
    "with row2_3:\n",
    "    str_jobs = \"💛 \" + str(len(filtered_df['job_title'].value_counts())) + \" Job Titles\"\n",
    "    st.markdown(str_jobs)\n",
    "with row2_4:\n",
    "    str_locations = \"💚 \" + str(len(filtered_df['location'].value_counts())) + \" Locations\"\n",
    "    st.markdown(str_locations)\n",
    "\n",
    "row3_spacer1, row3_1, row3_spacer2 = st.columns((.2, 7.1, .2))\n",
    "with row3_1:\n",
    "    st.markdown(\"\")\n",
    "    if filtered_df.shape[0] == 0:\n",
    "        st.warning('There is no result for your current selection.')\n",
    "    else:\n",
    "        see_data = st.expander('You can click here to see the raw data first 👉')\n",
    "        with see_data:\n",
    "            st.dataframe(data=filtered_df.iloc[:,:-2].sort_values(by=['firm','job_title']).reset_index(drop=True))\n",
    "st.text('')\n",
    "\n",
    "################\n",
    "### ANALYSIS ###\n",
    "################\n",
    "\n",
    "### RATINGS ###\n",
    "row4_spacer1, row4_1, row4_spacer2 = st.columns((.2, 7.1, .2))\n",
    "with row4_1:\n",
    "    st.subheader('Average Rating Analysis')\n",
    "row5_spacer1, row5_1, row5_spacer2, row5_2, row5_spacer3  = st.columns((.2, 2.3, .4, 4.4, .2))\n",
    "with row5_1:\n",
    "    st.text('')\n",
    "    st.markdown('The graph on the right shows the average rating of your selected reviews data across different aspects including Career Opportunities, Comp & Benefits, Culture & Values, Senior Management, and Work/Life Balance', unsafe_allow_html=True, )   \n",
    "    sort_rating = st.checkbox(\"Sort these ratings from high to low\")\n",
    "    st.text('')\n",
    "    compare_analysis_rating = st.checkbox(\"Compare this with another option\", key = \"compare_rating\")\n",
    "    if compare_analysis_rating:\n",
    "        filtered_df_2 = df.copy()\n",
    "        ### COMPANY ###\n",
    "        firm_options = sorted([x for x in filtered_df_2['firm'].unique() if x != ''])\n",
    "        firm = st.selectbox('First select the company you want to compare:', firm_options, key = \"option2_firm\")\n",
    "        filtered_df_2 = filtered_df_2[filtered_df_2['firm'] == firm]  \n",
    "        ### JOB TITLE ###\n",
    "        job_options = sorted([str(x) for x in filtered_df_2['job_title'].unique() if x != ''])\n",
    "        job_title = st.multiselect('Then select one or multiple job titles (optional):', job_options, key = \"option2_job\")\n",
    "        if job_title:\n",
    "            filtered_df_2 = filtered_df_2[filtered_df_2['job_title'].isin(job_title)]     \n",
    "        ### LOCATION ###\n",
    "        location_options = sorted([str(x) for x in filtered_df_2['location'].unique() if x != ''])\n",
    "        location = st.multiselect('Then select one or multiple locations (optional):', location_options, key = \"option2_loc\")\n",
    "        if location:\n",
    "            filtered_df_2 = filtered_df_2[filtered_df_2['location'].isin(location)]\n",
    "with row5_2:\n",
    "    plot_rating(filtered_df)\n",
    "\n",
    "### SENTIMENT ANALYSIS ###\n",
    "row6_spacer1, row6_1, row6_spacer2 = st.columns((.2, 7.1, .2))\n",
    "with row6_1:\n",
    "    st.subheader('Average Sentiment Analysis')\n",
    "row7_spacer1, row7_1, row7_spacer2, row7_2, row7_spacer3  = st.columns((.2, 2.3, .4, 4.4, .2))\n",
    "with row7_1:\n",
    "    st.text('')\n",
    "    st.markdown('sentiment_polarity: This is a measure of the sentiment polarity of the text, ranging from -1 (most negative) to 1 (most positive). A value of 0 indicates a neutral sentiment.', unsafe_allow_html=True, ) \n",
    "    st.markdown('sentiment_subjectivity: This is a measure of the subjectivity of the text, ranging from 0 (most objective) to 1 (most subjective). A value of 0 indicates an objective text, while a value of 1 indicates a highly subjective text.', unsafe_allow_html=True, )    \n",
    "    st.text('')\n",
    "    # compare_analysis = st.checkbox(\"Compare this with another option\", key = \"compare_sentiment\")\n",
    "with row7_2:\n",
    "    plot_sentiment(filtered_df)\n",
    "\n",
    "### PHRASE FREQUENCY ANALYSIS ###\n",
    "row8_spacer1, row8_1, row8_spacer2 = st.columns((.2, 7.1, .2))\n",
    "with row8_1:\n",
    "    st.subheader('Top Frequent Noun Phrases Analysis')\n",
    "row9_spacer1, row9_1, row9_spacer2, row9_2, row9_spacer3  = st.columns((.2, 2.3, .4, 4.4, .2))\n",
    "with row9_1:\n",
    "    st.text('')\n",
    "    st.markdown('Show top frequent noun phrases')    \n",
    "    scope = st.selectbox (\"Which piece of text do you want to analyze?\", ['all','pros','cons','headline'], key='unique_key_1')\n",
    "    n = st.select_slider (\"How many top phrases do you want to see?\", options=[5, 10, 15, 20, 25, 30], value=15)\n",
    "with row9_2:\n",
    "    plot_top_phrases(filtered_df)\n",
    "\n",
    "### WORDCLOUD ANALYSIS ###\n",
    "row10_spacer1, row10_1, row10_spacer2 = st.columns((.2, 7.1, .2))\n",
    "with row10_1:\n",
    "    st.subheader('Wordcloud Analysis')\n",
    "row11_spacer1, row11_1, row11_spacer2, row11_2, row11_spacer3  = st.columns((.2, 2.3, .4, 4.4, .2))\n",
    "with row11_1:\n",
    "    st.text('')   \n",
    "    scope_2 = st.selectbox (\"Which piece of text do you want to analyze?\", ['all','pros','cons','headline'], key='unique_key_2')\n",
    "    n_2 = st.select_slider (\"What is the maximum number of words you want to see?\", options=[50, 100, 150, 200], value=100)\n",
    "with row11_2:\n",
    "    plot_wordcloud(filtered_df)\n",
    "\n",
    "################\n",
    "### PREDICT ####\n",
    "################\n",
    "row12_spacer1, row12_1, row12_spacer2 = st.columns((.2, 7.1, .2))\n",
    "with row12_1:\n",
    "    st.subheader('Overall Rating Prediction')\n",
    "with st.form(key=\"my_form\"):\n",
    "    row13_spacer1, row13_1, row13_spacer2, row13_2, row13_spacer3, row13_3, row13_spacer4 = st.columns((.2, 2, .2, 2, .2, 2, .2))\n",
    "    with row13_1:\n",
    "        text_headline = st.text_area(\n",
    "        # Instructions\n",
    "        \"Please enter headline here\",\n",
    "        # 'sample' variable that contains our keyphrases.\n",
    "        \"Good firm!\",\n",
    "        # The height\n",
    "        height=200,\n",
    "        key=\"1\")\n",
    "    with row13_2:\n",
    "        text_pros = st.text_area(\n",
    "        # Instructions\n",
    "        \"Please enter pros here\",\n",
    "        # 'sample' variable that contains our keyphrases.\n",
    "        \"nice environment, friendly people\",\n",
    "        # The height\n",
    "        height=200,\n",
    "        key=\"2\")\n",
    "    with row13_3:\n",
    "        text_cons = st.text_area(\n",
    "        # Instructions\n",
    "        \"Please enter cons here\",\n",
    "        # 'sample' variable that contains our keyphrases.\n",
    "        \"no particular cons\",\n",
    "        # The height\n",
    "        height=200,\n",
    "        key=\"3\")\n",
    "        \n",
    "    submit_button = st.form_submit_button(label=\"Submit\")\n",
    "    \n",
    "### CONDITIONAL STATEMENTS ###\n",
    "if submit_button and text_headline == '' and text_pros == '' and text_cons == '':\n",
    "     st.warning(\"❄️ Please make sure to input something for rating prediction\")\n",
    "elif submit_button:\n",
    "    from joblib import load\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    import scipy\n",
    "    from scipy.sparse import hstack\n",
    "\n",
    "    test_df = pd.DataFrame({\n",
    "    'headline': [text_headline],\n",
    "    'pros': [text_pros],\n",
    "    'cons': [text_cons]\n",
    "    })\n",
    "    \n",
    "    # Load the saved model from a file\n",
    "    logreg = load('C:/Users/lenovo/Documents/KaggleX/logreg_model.joblib')\n",
    "\n",
    "    # Use the loaded model to make predictions\n",
    "    test_features_lst = []\n",
    "    for i in ['headline', 'pros', 'cons']:\n",
    "        tfidf_vectorizer = load('C:/Users/lenovo/Documents/KaggleX/'+i+'_vectorizer.joblib')\n",
    "        test_features = tfidf_vectorizer.transform(test_df[i].values)\n",
    "        test_features_lst.append(test_features)\n",
    "\n",
    "    X_test = hstack(test_features_lst)\n",
    "    y_pred = logreg.predict(X_test)\n",
    "    st.success(\"✅ Done! \" + \"The rating of this company is predicted to be \" + y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!streamlit run myapp.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
